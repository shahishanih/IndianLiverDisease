{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Importing the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data wherev header is not given and it is space sperated text and 1st column is index.\n",
    "df=pd.read_csv(r\"C:\\Users\\DELL\\Downloads\\IndianLiverPatientData.txt\", header=None, delimiter= ' *\\t *',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581</td>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>245</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>184</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583</td>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1       2     3    4    5   6    7    8    9     10   11\n",
       "0                                                            \n",
       "1    65  Female   0.7  0.1  187  16   18  6.8  3.3  0.90   No\n",
       "2    62    Male  10.9  5.5  699  64  100  7.5  3.2  0.74   No\n",
       "3    62    Male   7.3  4.1  490  60   68  7.0  3.3  0.89   No\n",
       "4    58    Male   1.0  0.4  182  14   20  6.8  3.4  1.00   No\n",
       "5    72    Male   3.9  2.0  195  27   59  7.3  2.4  0.40   No\n",
       "..   ..     ...   ...  ...  ...  ..  ...  ...  ...   ...  ...\n",
       "579  60    Male   0.5  0.1  500  20   34  5.9  1.6  0.37  Yes\n",
       "580  40    Male   0.6  0.1   98  35   31  6.0  3.2  1.10   No\n",
       "581  52    Male   0.8  0.2  245  48   49  6.4  3.2  1.00   No\n",
       "582  31    Male   1.3  0.5  184  29   32  6.8  3.4  1.00   No\n",
       "583  38    Male   1.0  0.3  216  21   24  7.3  4.4  1.50  Yes\n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cheching for the shape of the data frame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giving the dataframe the column names\n",
    "df.columns=['Age','Gender','Total_Bilirubin','Direct_Bilirubin','Alkaline_Phosphotase',\n",
    "'Alamine_Aminotransferase','Aspartate_Aminotransferase','Total_Protiens','Albumin',\n",
    "'Albumin_and_Globulin_Ratio','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0                                                                         \n",
       "1   65  Female              0.7               0.1                   187   \n",
       "2   62    Male             10.9               5.5                   699   \n",
       "3   62    Male              7.3               4.1                   490   \n",
       "4   58    Male              1.0               0.4                   182   \n",
       "5   72    Male              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                                                                         \n",
       "1                        16                          18             6.8   \n",
       "2                        64                         100             7.5   \n",
       "3                        60                          68             7.0   \n",
       "4                        14                          20             6.8   \n",
       "5                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio Class  \n",
       "0                                             \n",
       "1      3.3                        0.90    No  \n",
       "2      3.2                        0.74    No  \n",
       "3      3.3                        0.89    No  \n",
       "4      3.4                        1.00    No  \n",
       "5      2.4                        0.40    No  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for the outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.boxplot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Outlier for Individual Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91ca0f08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=\"Direct_Bilirubin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91d5b848>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=\"Total_Bilirubin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91dd9f88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=\"Alkaline_Phosphotase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91b91288>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=\"Alamine_Aminotransferase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91c91dc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=\"Total_Protiens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91e3ba48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKC0lEQVR4nO3dX4il913H8c+3SbAhDRWbdBATMhcFLUZqdOyFERmDlmKKKHjRgIJQ2NsIikZvasWLeGO9UMFFxfinBrENShbXBswhpGrqbm01caNiTaGkGNNgTWKITfr1YmfzZzPrnMnOM/Nd9/WCYc7Zec7zfAeefc/Db86ZU90dAOZ6y1EPAMD/TagBhhNqgOGEGmA4oQYY7soldnrdddf15ubmEruGi/L888/nmmuuOeox4A1Onz79dHdfv9vXFgn15uZmTp06tcSu4aKsVqtsb28f9RjwBlX1hQt9zdIHwHBCDTCcUAMMJ9QAwwk1wHBCDTCcUAMMJ9QAwy3yghc4DFV1aMfyd9s5Sq6ouWR1974/bvrZ+9/U4+AoCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcGu9FVdVPZHk2SQvJ3mpu7eWHAqAV+3nPRO/r7ufXmwSAHZl6QNguHWvqDvJJ6uqk/xmdx8/f4OqOpbkWJJsbGxktVod2JBwkJybXGrWDfWt3f1kVb0zyQNV9Xh3P/TaDXbifTxJtra2ent7+2AnhYNw8kScm1xq1lr66O4ndz4/leS+JO9dcigAXrVnqKvqmqq69tztJO9L8ujSgwFw1jpLHxtJ7quqc9t/rLtPLjoVAK/YM9Td/fkk7zmEWQDYhafnAQwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDrR3qqrqiqv6uqu5fciAAXm8/V9R3Jjmz1CAA7G6tUFfVDUluT/Jby44DwPmuXHO7X03yM0muvdAGVXUsybEk2djYyGq1uujhYAnOTS41e4a6qj6Q5KnuPl1V2xfarruPJzmeJFtbW729fcFN4eicPBHnJpeadZY+bk3yQ1X1RJJ7k9xWVX+w6FQAvGLPUHf3z3X3Dd29meSDSf6yu39s8ckASOJ51ADjrfvLxCRJd6+SrBaZBIBduaIGGE6oAYbb19IHLOk9H/lkvvLCVxc/zuZdJxbd/9uvviqf+/D7Fj0GlxehZoyvvPDVPHH37YseY7VaLf486qV/EHD5sfQBMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcFce9QBwzrXvvivfds9dyx/onmV3f+27k+T2ZQ/CZUWoGePZM3fnibuXDdxqtcr29vaix9i868Si++fys+fSR1W9tao+XVWfq6rHquojhzEYAGetc0X9YpLbuvu5qroqycNV9efd/TcLzwZA1gh1d3eS53buXrXz0UsOBcCr1lqjrqorkpxO8q4kv97dj+yyzbEkx5JkY2Mjq9XqAMfkcrH0efPcc88dyrnp/OcgrRXq7n45ybdX1dcnua+qbu7uR8/b5niS40mytbXVS//Chv+HTp5Y/Bd9h/HLxMP4Pri87Ot51N39n0lWSd6/yDQAvME6z/q4fudKOlV1dZLvT/L40oMBcNY6Sx/fmOSenXXqtyT54+6+f9mxADhnnWd9/H2SWw5hFgB24W99AAwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADDCTXAcN7cllEO5Y1hTy57jLdffdWi++fyI9SMsfQ7kCdnfxAcxnHgIFn6ABhOqAGGE2qA4YQaYDihBhhOqAGGE2qA4YQaYDihBhhOqAGGE2qA4YQaYDihBhhOqAGGE2qA4YQaYDihBhhOqAGGE2qA4YQaYLg9Q11VN1bVg1V1pqoeq6o7D2MwAM5a513IX0ryU939maq6Nsnpqnqgu/9x4dkAyBpX1N39pe7+zM7tZ5OcSfJNSw8GwFn7WqOuqs0ktyR5ZIlhAHijdZY+kiRV9bYkH0/yk939X7t8/ViSY0mysbGR1Wp1UDPCgXJucqmp7t57o6qrktyf5C+6+1f22n5ra6tPnTp1AOPBwdq860SeuPv2ox4D3qCqTnf31m5fW+dZH5Xkt5OcWSfSABysddaob03y40luq6rP7nz84MJzAbBjzzXq7n44SR3CLADswisTAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDhhBpgOKEGGE6oAYYTaoDh9gx1Vf1OVT1VVY8exkAAvN46V9S/m+T9C88BwAXsGerufijJM4cwCwC7sEYNMNyVB7WjqjqW5FiSbGxsZLVaHdSu4UA5N7nUHFiou/t4kuNJsrW11dvb2we1azg4J0/EucmlxtIHwHDrPD3vj5L8dZJvrqovVtWHlh8LgHP2XPro7jsOYxDYr6p6c4/75f0/prvf1LHgIFj64JLV3fv+ePDBB9/U4+AoCTXAcEINMJxQAwwn1ADDCTXAcEINMJxQAwwn1ADD1RJP5q+q/0jyhQPfMVy865I8fdRDwC5u6u7rd/vCIqGGqarqVHdvHfUcsB+WPgCGE2qA4YSay83xox4A9ssaNcBwrqgBhhNqgOGEmvGq6keqqqvqW3bub1bVozu3f6Kqfm2h4/7VEvuF/RJqLgV3JHk4yQcP86Dd/d2HeTy4EKFmtKp6W5Jbk3woFw71jVV1sqr+qao+vPO4V666d+7/dFX9ws7tVVV9tKoeqqozVfVdVfWJqvqXqvql1zzmuZ3P2zuP+ZOqeryq/rDe7Bs2wpuw55vbwhH74SQnu/ufq+qZqvqOJM+ct817k9yc5L+T/G1VncjeLxP/n+7+3qq6M8mfJvnOnf3+a1V9tLu/fN72tyT51iRPJvlUzv7wePhivjFYlytqprsjyb07t+/duX++B7r7y939QpJPJPmeNfb7Zzuf/yHJY939pe5+Mcnnk9y4y/af7u4vdvfXknw2yeY+vge4KK6oGauq3pHktiQ3V1UnuSJJJ/mN8zY9/8UAneSlvP5C5K3nbfPizuevveb2ufu7/b947TYvX2AbWIQraib70SS/1903dfdmd9+Y5N+S3HDedj9QVd9QVVfn7FLJp5L8e5J3VtU7qurrknzgUCeHA+SqgMnuSHL3ef/28SQ/f96/PZzk95O8K8nHuvtUklTVLyZ5JGfj/viyo8JyvIQcYDhLHwDDCTXAcEINMJxQAwwn1ADDCTXAcEINMNz/Am4dhPZBbjUDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df.boxplot(column=\"Albumin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2cc91eac0c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(column=\"Albumin_and_Globulin_Ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                            0\n",
       "Gender                        20\n",
       "Total_Bilirubin                0\n",
       "Direct_Bilirubin               0\n",
       "Alkaline_Phosphotase           0\n",
       "Alamine_Aminotransferase       0\n",
       "Aspartate_Aminotransferase     0\n",
       "Total_Protiens                15\n",
       "Albumin                        0\n",
       "Albumin_and_Globulin_Ratio     4\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].fillna(df[\"Gender\"].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in [\"Albumin_and_Globulin_Ratio\",\"Total_Protiens\"]:\n",
    "    df[value].fillna(df[value].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "Gender                        0\n",
       "Total_Bilirubin               0\n",
       "Direct_Bilirubin              0\n",
       "Alkaline_Phosphotase          0\n",
       "Alamine_Aminotransferase      0\n",
       "Aspartate_Aminotransferase    0\n",
       "Total_Protiens                0\n",
       "Albumin                       0\n",
       "Albumin_and_Globulin_Ratio    0\n",
       "Class                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender', 'Class']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#created an array which stoes the variable which has the data type as object\n",
    "colname=[]\n",
    "for x in df.columns:\n",
    "    if df[x].dtype==\"object\":\n",
    "        colname.append(x)\n",
    "colname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder is used to convert the Categorical data into numerical data\n",
    "from sklearn import preprocessing \n",
    "le=preprocessing.LabelEncoder()\n",
    "for x in colname:\n",
    "    df[x]=le.fit_transform(df[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>208</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>154</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>202</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>290</td>\n",
       "      <td>53</td>\n",
       "      <td>58</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0                                                                          \n",
       "1    65       0              0.7               0.1                   187   \n",
       "2    62       1             10.9               5.5                   699   \n",
       "3    62       1              7.3               4.1                   490   \n",
       "4    58       1              1.0               0.4                   182   \n",
       "5    72       1              3.9               2.0                   195   \n",
       "6    46       1              1.8               0.7                   208   \n",
       "7    26       0              0.9               0.2                   154   \n",
       "8    29       0              0.9               0.3                   202   \n",
       "9    17       1              0.9               0.3                   202   \n",
       "10   55       1              0.7               0.2                   290   \n",
       "\n",
       "    Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                                                                          \n",
       "1                         16                          18             6.8   \n",
       "2                         64                         100             7.5   \n",
       "3                         60                          68             7.0   \n",
       "4                         14                          20             6.8   \n",
       "5                         27                          59             7.3   \n",
       "6                         19                          14             7.6   \n",
       "7                         16                          12             7.0   \n",
       "8                         14                          11             6.7   \n",
       "9                         22                          19             7.4   \n",
       "10                        53                          58             6.8   \n",
       "\n",
       "    Albumin  Albumin_and_Globulin_Ratio  Class  \n",
       "0                                               \n",
       "1       3.3                        0.90      0  \n",
       "2       3.2                        0.74      0  \n",
       "3       3.3                        0.89      0  \n",
       "4       3.4                        1.00      0  \n",
       "5       2.4                        0.40      0  \n",
       "6       4.4                        1.30      0  \n",
       "7       3.5                        1.00      0  \n",
       "8       3.6                        1.10      0  \n",
       "9       4.1                        1.20      1  \n",
       "10      3.4                        1.00      0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X and Y variable of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "Y=df.iloc[:,-1]\n",
    "Y=Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(583, 10)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.25209764, -1.76228085, -0.41887783, ...,  0.30646825,\n",
       "         0.19896867, -0.14902528],\n",
       "       [ 1.06663704,  0.56744644,  1.22517135, ...,  0.95957369,\n",
       "         0.07315659, -0.65177676],\n",
       "       [ 1.06663704,  0.56744644,  0.6449187 , ...,  0.4930698 ,\n",
       "         0.19896867, -0.18044725],\n",
       "       ...,\n",
       "       [ 0.44843504,  0.56744644, -0.4027597 , ..., -0.06673486,\n",
       "         0.07315659,  0.16519439],\n",
       "       [-0.84978917,  0.56744644, -0.32216906, ...,  0.30646825,\n",
       "         0.32478075,  0.16519439],\n",
       "       [-0.41704777,  0.56744644, -0.37052344, ...,  0.77297214,\n",
       "         1.58290153,  1.73629275]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40646699 -0.01187005 -0.27458957 -0.84001423 -0.37925855 -1.19746557\n",
      "  -0.7660016  -0.46498272  0.55011611 -0.13030448]]\n",
      "[-1.62840828]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)\n",
    "#print(list(zip(Y_test,Y_pred)))\n",
    "print(classifier.coef_)#coef is used to know the value of the coefficient which is nothing but the change in the value with the value change\n",
    "print(classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.39531790e-01 2.60468210e-01]\n",
      " [9.86843392e-01 1.31566076e-02]\n",
      " [3.95872912e-01 6.04127088e-01]\n",
      " [8.30774337e-01 1.69225663e-01]\n",
      " [6.30956915e-01 3.69043085e-01]\n",
      " [5.33775227e-01 4.66224773e-01]\n",
      " [5.31787525e-01 4.68212475e-01]\n",
      " [9.00313949e-01 9.96860509e-02]\n",
      " [6.46063204e-01 3.53936796e-01]\n",
      " [9.99999286e-01 7.13702228e-07]\n",
      " [9.96233116e-01 3.76688388e-03]\n",
      " [4.39861884e-01 5.60138116e-01]\n",
      " [7.86531366e-01 2.13468634e-01]\n",
      " [6.57445941e-01 3.42554059e-01]\n",
      " [8.62546033e-01 1.37453967e-01]\n",
      " [9.88108003e-01 1.18919974e-02]\n",
      " [4.00529862e-01 5.99470138e-01]\n",
      " [7.18939802e-01 2.81060198e-01]\n",
      " [9.11504080e-01 8.84959202e-02]\n",
      " [7.50255086e-01 2.49744914e-01]\n",
      " [5.04953955e-01 4.95046045e-01]\n",
      " [7.52034446e-01 2.47965554e-01]\n",
      " [7.59548123e-01 2.40451877e-01]\n",
      " [3.88252631e-01 6.11747369e-01]\n",
      " [7.25346534e-01 2.74653466e-01]\n",
      " [7.52243666e-01 2.47756334e-01]\n",
      " [7.23347969e-01 2.76652031e-01]\n",
      " [7.28920682e-01 2.71079318e-01]\n",
      " [9.99871842e-01 1.28157892e-04]\n",
      " [6.18701558e-01 3.81298442e-01]\n",
      " [8.12116083e-01 1.87883917e-01]\n",
      " [7.94276466e-01 2.05723534e-01]\n",
      " [6.87909579e-01 3.12090421e-01]\n",
      " [4.73276379e-01 5.26723621e-01]\n",
      " [5.05162199e-01 4.94837801e-01]\n",
      " [8.75888668e-01 1.24111332e-01]\n",
      " [8.29888210e-01 1.70111790e-01]\n",
      " [4.47419343e-01 5.52580657e-01]\n",
      " [8.51035603e-01 1.48964397e-01]\n",
      " [4.42066969e-01 5.57933031e-01]\n",
      " [9.97777136e-01 2.22286407e-03]\n",
      " [5.84573837e-01 4.15426163e-01]\n",
      " [5.86129799e-01 4.13870201e-01]\n",
      " [6.28815622e-01 3.71184378e-01]\n",
      " [8.78184941e-01 1.21815059e-01]\n",
      " [9.84651960e-01 1.53480404e-02]\n",
      " [7.86011441e-01 2.13988559e-01]\n",
      " [4.60098106e-01 5.39901894e-01]\n",
      " [9.99997937e-01 2.06292664e-06]\n",
      " [6.17220281e-01 3.82779719e-01]\n",
      " [9.85419716e-01 1.45802838e-02]\n",
      " [6.49203902e-01 3.50796098e-01]\n",
      " [6.24490074e-01 3.75509926e-01]\n",
      " [9.98591618e-01 1.40838155e-03]\n",
      " [7.75155850e-01 2.24844150e-01]\n",
      " [7.50536160e-01 2.49463840e-01]\n",
      " [7.40015546e-01 2.59984454e-01]\n",
      " [6.17220281e-01 3.82779719e-01]\n",
      " [8.14611856e-01 1.85388144e-01]\n",
      " [8.69303908e-01 1.30696092e-01]\n",
      " [5.37589063e-01 4.62410937e-01]\n",
      " [6.76562252e-01 3.23437748e-01]\n",
      " [6.75098791e-01 3.24901209e-01]\n",
      " [6.63874572e-01 3.36125428e-01]\n",
      " [9.94366510e-01 5.63348951e-03]\n",
      " [4.39399542e-01 5.60600458e-01]\n",
      " [8.49266563e-01 1.50733437e-01]\n",
      " [4.25671849e-01 5.74328151e-01]\n",
      " [4.55193726e-01 5.44806274e-01]\n",
      " [7.63510616e-01 2.36489384e-01]\n",
      " [6.04372269e-01 3.95627731e-01]\n",
      " [5.97060127e-01 4.02939873e-01]\n",
      " [3.13738293e-01 6.86261707e-01]\n",
      " [6.40981260e-01 3.59018740e-01]\n",
      " [5.83964452e-01 4.16035548e-01]\n",
      " [5.25433835e-01 4.74566165e-01]\n",
      " [6.73289977e-01 3.26710023e-01]\n",
      " [5.25756866e-01 4.74243134e-01]\n",
      " [5.82554708e-01 4.17445292e-01]\n",
      " [4.03354249e-01 5.96645751e-01]\n",
      " [9.11353181e-01 8.86468185e-02]\n",
      " [7.63924568e-01 2.36075432e-01]\n",
      " [9.99454877e-01 5.45122743e-04]\n",
      " [9.20071314e-01 7.99286861e-02]\n",
      " [9.41521573e-01 5.84784273e-02]\n",
      " [5.82537959e-01 4.17462041e-01]\n",
      " [7.95786396e-01 2.04213604e-01]\n",
      " [5.98951669e-01 4.01048331e-01]\n",
      " [7.00556860e-01 2.99443140e-01]\n",
      " [9.88224263e-01 1.17757373e-02]\n",
      " [8.47726169e-01 1.52273831e-01]\n",
      " [6.85703033e-01 3.14296967e-01]\n",
      " [6.09820083e-01 3.90179917e-01]\n",
      " [5.94736941e-01 4.05263059e-01]\n",
      " [6.68475624e-01 3.31524376e-01]\n",
      " [9.70090781e-01 2.99092188e-02]\n",
      " [9.95885413e-01 4.11458723e-03]\n",
      " [7.88684553e-01 2.11315447e-01]\n",
      " [7.39366576e-01 2.60633424e-01]\n",
      " [4.58835341e-01 5.41164659e-01]\n",
      " [5.72813593e-01 4.27186407e-01]\n",
      " [9.93326426e-01 6.67357412e-03]\n",
      " [5.34457729e-01 4.65542271e-01]\n",
      " [5.44578228e-01 4.55421772e-01]\n",
      " [9.15025191e-01 8.49748087e-02]\n",
      " [9.23352968e-01 7.66470323e-02]\n",
      " [8.84398733e-01 1.15601267e-01]\n",
      " [6.27498487e-01 3.72501513e-01]\n",
      " [7.18304164e-01 2.81695836e-01]\n",
      " [6.07688854e-01 3.92311146e-01]\n",
      " [6.79690246e-01 3.20309754e-01]\n",
      " [9.96181999e-01 3.81800141e-03]\n",
      " [8.14916467e-01 1.85083533e-01]\n",
      " [6.89851253e-01 3.10148747e-01]\n",
      " [8.25028916e-01 1.74971084e-01]\n",
      " [7.22006995e-01 2.77993005e-01]\n",
      " [7.40497379e-01 2.59502621e-01]\n",
      " [6.10446574e-01 3.89553426e-01]\n",
      " [5.63571916e-01 4.36428084e-01]\n",
      " [7.16636312e-01 2.83363688e-01]\n",
      " [8.64434531e-01 1.35565469e-01]\n",
      " [7.58305445e-01 2.41694555e-01]\n",
      " [9.40363198e-01 5.96368022e-02]\n",
      " [9.08051809e-01 9.19481907e-02]\n",
      " [4.37892105e-01 5.62107895e-01]\n",
      " [9.90528539e-01 9.47146070e-03]\n",
      " [6.56474277e-01 3.43525723e-01]\n",
      " [6.01632928e-01 3.98367072e-01]\n",
      " [9.99988830e-01 1.11700399e-05]\n",
      " [5.46880986e-01 4.53119014e-01]\n",
      " [9.98542909e-01 1.45709063e-03]\n",
      " [9.98876266e-01 1.12373391e-03]\n",
      " [8.56788460e-01 1.43211540e-01]\n",
      " [9.49539820e-01 5.04601796e-02]\n",
      " [9.99999844e-01 1.56418044e-07]\n",
      " [4.00386591e-01 5.99613409e-01]\n",
      " [6.53686710e-01 3.46313290e-01]\n",
      " [6.80016504e-01 3.19983496e-01]\n",
      " [6.70532232e-01 3.29467768e-01]\n",
      " [7.95886888e-01 2.04113112e-01]\n",
      " [6.97838243e-01 3.02161757e-01]\n",
      " [9.84737053e-01 1.52629475e-02]\n",
      " [3.57101511e-01 6.42898489e-01]\n",
      " [4.55809669e-01 5.44190331e-01]\n",
      " [6.16487834e-01 3.83512166e-01]\n",
      " [8.56115565e-01 1.43884435e-01]\n",
      " [7.20393133e-01 2.79606867e-01]\n",
      " [8.43495344e-01 1.56504656e-01]\n",
      " [4.97216709e-01 5.02783291e-01]\n",
      " [6.13965980e-01 3.86034020e-01]\n",
      " [9.99898482e-01 1.01518337e-04]\n",
      " [6.71617323e-01 3.28382677e-01]\n",
      " [8.28787516e-01 1.71212484e-01]\n",
      " [8.56894882e-01 1.43105118e-01]\n",
      " [9.99652243e-01 3.47756538e-04]\n",
      " [7.04954698e-01 2.95045302e-01]\n",
      " [6.43835069e-01 3.56164931e-01]\n",
      " [7.94750909e-01 2.05249091e-01]\n",
      " [6.00985973e-01 3.99014027e-01]\n",
      " [4.58444547e-01 5.41555453e-01]\n",
      " [7.54405215e-01 2.45594785e-01]\n",
      " [7.92061616e-01 2.07938384e-01]\n",
      " [6.03875646e-01 3.96124354e-01]\n",
      " [6.28534017e-01 3.71465983e-01]\n",
      " [4.32520531e-01 5.67479469e-01]\n",
      " [9.99999206e-01 7.94136135e-07]\n",
      " [6.78972573e-01 3.21027427e-01]\n",
      " [9.94299653e-01 5.70034679e-03]\n",
      " [8.88884999e-01 1.11115001e-01]\n",
      " [5.15367404e-01 4.84632596e-01]\n",
      " [6.78419216e-01 3.21580784e-01]\n",
      " [9.92581370e-01 7.41863028e-03]\n",
      " [7.84632714e-01 2.15367286e-01]\n",
      " [9.68743079e-01 3.12569206e-02]\n",
      " [7.15070599e-01 2.84929401e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0---->No\n",
    "#1---->yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  12]\n",
      " [ 40   9]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       126\n",
      "           1       0.43      0.18      0.26        49\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.58      0.54      0.54       175\n",
      "weighted avg       0.65      0.70      0.66       175\n",
      "\n",
      "Accracy of the model: 0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusting the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors at threshold  0.4 : 57  , type 2 error : 32  , type 1 error: 25\n",
      "Errors at threshold  0.41000000000000003 : 56  , type 2 error : 33  , type 1 error: 23\n",
      "Errors at threshold  0.42000000000000004 : 55  , type 2 error : 35  , type 1 error: 20\n",
      "Errors at threshold  0.43000000000000005 : 56  , type 2 error : 36  , type 1 error: 20\n",
      "Errors at threshold  0.44000000000000006 : 55  , type 2 error : 36  , type 1 error: 19\n",
      "Errors at threshold  0.45000000000000007 : 55  , type 2 error : 36  , type 1 error: 19\n",
      "Errors at threshold  0.4600000000000001 : 55  , type 2 error : 37  , type 1 error: 18\n",
      "Errors at threshold  0.4700000000000001 : 53  , type 2 error : 38  , type 1 error: 15\n",
      "Errors at threshold  0.4800000000000001 : 51  , type 2 error : 38  , type 1 error: 13\n",
      "Errors at threshold  0.4900000000000001 : 50  , type 2 error : 38  , type 1 error: 12\n",
      "Errors at threshold  0.5000000000000001 : 52  , type 2 error : 40  , type 1 error: 12\n",
      "Errors at threshold  0.5100000000000001 : 51  , type 2 error : 40  , type 1 error: 11\n",
      "Errors at threshold  0.5200000000000001 : 51  , type 2 error : 40  , type 1 error: 11\n",
      "Errors at threshold  0.5300000000000001 : 52  , type 2 error : 41  , type 1 error: 11\n",
      "Errors at threshold  0.5400000000000001 : 51  , type 2 error : 41  , type 1 error: 10\n",
      "Errors at threshold  0.5500000000000002 : 49  , type 2 error : 42  , type 1 error: 7\n",
      "Errors at threshold  0.5600000000000002 : 49  , type 2 error : 43  , type 1 error: 6\n",
      "Errors at threshold  0.5700000000000002 : 47  , type 2 error : 44  , type 1 error: 3\n",
      "Errors at threshold  0.5800000000000002 : 48  , type 2 error : 45  , type 1 error: 3\n",
      "Errors at threshold  0.5900000000000002 : 48  , type 2 error : 45  , type 1 error: 3\n",
      "Errors at threshold  0.6000000000000002 : 49  , type 2 error : 47  , type 1 error: 2\n"
     ]
    }
   ],
   "source": [
    "for a in np.arange(0.4,0.61,0.01):\n",
    "    predict_mine = np.where(y_pred_prob[:,1] > a, 1, 0)\n",
    "    cfm=confusion_matrix(Y_test, predict_mine)\n",
    "    total_err=cfm[0,1]+cfm[1,0]\n",
    "    print(\"Errors at threshold \", a, \":\",total_err, \" , type 2 error :\",\n",
    "    cfm[1,0],\" , type 1 error:\", cfm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class=[]\n",
    "for value in y_pred_prob[:,1]:\n",
    "    if value >0.57:\n",
    "        y_pred_class.append(1)\n",
    "    else:\n",
    "        y_pred_class.append(0)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  12]\n",
      " [ 40   9]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       126\n",
      "           1       0.43      0.18      0.26        49\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.58      0.54      0.54       175\n",
      "weighted avg       0.65      0.70      0.66       175\n",
      "\n",
      "Accracy of the model: 0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    416\n",
       "1    167\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    416\n",
       "0    416\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.Class==0]\n",
    "df_minority = df[df.Class==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "replace=True, # sample with replacement\n",
    "n_samples=416, # to match majority class\n",
    "random_state=10) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "df_upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X And Y on upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65.  ,  0.  ,  0.7 , ...,  6.8 ,  3.3 ,  0.9 ],\n",
       "       [62.  ,  1.  , 10.9 , ...,  7.5 ,  3.2 ,  0.74],\n",
       "       [62.  ,  1.  ,  7.3 , ...,  7.  ,  3.3 ,  0.89],\n",
       "       ...,\n",
       "       [41.  ,  0.  ,  0.9 , ...,  7.6 ,  3.8 ,  1.  ],\n",
       "       [30.  ,  0.  ,  0.8 , ...,  7.9 ,  4.5 ,  1.3 ],\n",
       "       [35.  ,  1.  ,  0.9 , ...,  6.4 ,  3.6 ,  1.2 ]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_upsampled.values[:,:-1]\n",
    "Y=df_upsampled.values[:,-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31929811 -1.73762012 -0.36813594 ...  0.26926117  0.12505717\n",
      "  -0.20620087]\n",
      " [ 1.13104244  0.57549978  1.55193588 ...  0.91887886  0.00192396\n",
      "  -0.71584551]\n",
      " [ 1.13104244  0.57549978  0.87426347 ...  0.45486623  0.12505717\n",
      "  -0.23805366]\n",
      " ...\n",
      " [-0.18674721 -1.73762012 -0.33048747 ...  1.01168138  0.74072321\n",
      "   0.11232703]\n",
      " [-0.87701797 -1.73762012 -0.34931171 ...  1.29008896  1.60265568\n",
      "   1.06791072]\n",
      " [-0.56325853  0.57549978 -0.33048747 ... -0.10194893  0.4944568\n",
      "   0.74938282]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression On upsampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39993428  0.05188035 -0.32275944 -0.95320255 -0.20368103 -1.58843149\n",
      "  -0.85348785 -0.19373896  0.25520743 -0.13609385]]\n",
      "[-0.51741148]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,Y_train)\n",
    "Y_pred=classifier.predict(X_test)\n",
    "#print(list(zip(Y_test,Y_pred)))\n",
    "print(classifier.coef_)#coef is used to know the value of the coefficient which is nothing but the change in the value with the value change\n",
    "print(classifier.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.24372349e-01 7.75627651e-01]\n",
      " [9.99631113e-01 3.68886763e-04]\n",
      " [4.88740240e-01 5.11259760e-01]\n",
      " [2.18506102e-01 7.81493898e-01]\n",
      " [2.47915849e-01 7.52084151e-01]\n",
      " [5.18172789e-01 4.81827211e-01]\n",
      " [3.69562602e-01 6.30437398e-01]\n",
      " [4.31324826e-01 5.68675174e-01]\n",
      " [6.69262057e-01 3.30737943e-01]\n",
      " [9.96379818e-01 3.62018172e-03]\n",
      " [3.34862489e-01 6.65137511e-01]\n",
      " [3.38912010e-01 6.61087990e-01]\n",
      " [3.49300139e-01 6.50699861e-01]\n",
      " [5.43513254e-01 4.56486746e-01]\n",
      " [7.96039229e-01 2.03960771e-01]\n",
      " [2.87515126e-01 7.12484874e-01]\n",
      " [4.18448372e-01 5.81551628e-01]\n",
      " [2.63407965e-01 7.36592035e-01]\n",
      " [3.29817670e-01 6.70182330e-01]\n",
      " [5.42586798e-01 4.57413202e-01]\n",
      " [5.04725021e-01 4.95274979e-01]\n",
      " [2.72673814e-01 7.27326186e-01]\n",
      " [3.02319227e-01 6.97680773e-01]\n",
      " [4.80823090e-01 5.19176910e-01]\n",
      " [4.18448372e-01 5.81551628e-01]\n",
      " [9.77812116e-01 2.21878839e-02]\n",
      " [7.65070698e-01 2.34929302e-01]\n",
      " [3.73404542e-01 6.26595458e-01]\n",
      " [2.66339994e-01 7.33660006e-01]\n",
      " [4.85830020e-01 5.14169980e-01]\n",
      " [5.78805737e-01 4.21194263e-01]\n",
      " [3.56607859e-01 6.43392141e-01]\n",
      " [3.99083656e-01 6.00916344e-01]\n",
      " [4.91751041e-01 5.08248959e-01]\n",
      " [5.20838515e-01 4.79161485e-01]\n",
      " [5.08199357e-01 4.91800643e-01]\n",
      " [2.23244371e-01 7.76755629e-01]\n",
      " [4.15562184e-01 5.84437816e-01]\n",
      " [4.28023758e-01 5.71976242e-01]\n",
      " [3.51914540e-01 6.48085460e-01]\n",
      " [3.57409040e-01 6.42590960e-01]\n",
      " [5.96530379e-01 4.03469621e-01]\n",
      " [9.99061632e-01 9.38367666e-04]\n",
      " [8.82297854e-01 1.17702146e-01]\n",
      " [4.28173696e-01 5.71826304e-01]\n",
      " [2.79203061e-01 7.20796939e-01]\n",
      " [8.53738180e-01 1.46261820e-01]\n",
      " [4.57910713e-01 5.42089287e-01]\n",
      " [5.86496054e-01 4.13503946e-01]\n",
      " [7.08501601e-01 2.91498399e-01]\n",
      " [9.99804097e-01 1.95902891e-04]\n",
      " [9.99967855e-01 3.21453738e-05]\n",
      " [4.83907816e-01 5.16092184e-01]\n",
      " [2.88746804e-01 7.11253196e-01]\n",
      " [6.24023031e-01 3.75976969e-01]\n",
      " [5.78805737e-01 4.21194263e-01]\n",
      " [4.09448623e-01 5.90551377e-01]\n",
      " [9.98631186e-01 1.36881446e-03]\n",
      " [4.84956882e-01 5.15043118e-01]\n",
      " [2.96650910e-01 7.03349090e-01]\n",
      " [4.69154812e-01 5.30845188e-01]\n",
      " [8.86565812e-01 1.13434188e-01]\n",
      " [3.38551034e-01 6.61448966e-01]\n",
      " [2.65584960e-01 7.34415040e-01]\n",
      " [5.03830898e-01 4.96169102e-01]\n",
      " [5.61974933e-01 4.38025067e-01]\n",
      " [2.28606049e-01 7.71393951e-01]\n",
      " [3.77629091e-01 6.22370909e-01]\n",
      " [4.10082231e-01 5.89917769e-01]\n",
      " [4.54162896e-01 5.45837104e-01]\n",
      " [9.47955959e-01 5.20440409e-02]\n",
      " [2.29331297e-01 7.70668703e-01]\n",
      " [2.57972056e-01 7.42027944e-01]\n",
      " [4.20632118e-01 5.79367882e-01]\n",
      " [9.99567011e-01 4.32988611e-04]\n",
      " [3.99083656e-01 6.00916344e-01]\n",
      " [3.38912010e-01 6.61087990e-01]\n",
      " [3.52082280e-01 6.47917720e-01]\n",
      " [7.50940725e-01 2.49059275e-01]\n",
      " [3.24066588e-01 6.75933412e-01]\n",
      " [9.93919667e-01 6.08033287e-03]\n",
      " [5.46951646e-01 4.53048354e-01]\n",
      " [5.01484591e-01 4.98515409e-01]\n",
      " [6.22230657e-01 3.77769343e-01]\n",
      " [4.36582558e-01 5.63417442e-01]\n",
      " [2.91835444e-01 7.08164556e-01]\n",
      " [6.04883254e-01 3.95116746e-01]\n",
      " [4.24782854e-01 5.75217146e-01]\n",
      " [3.57395574e-01 6.42604426e-01]\n",
      " [3.39944942e-01 6.60055058e-01]\n",
      " [2.99653048e-01 7.00346952e-01]\n",
      " [3.99182697e-01 6.00817303e-01]\n",
      " [3.38912010e-01 6.61087990e-01]\n",
      " [2.95360065e-01 7.04639935e-01]\n",
      " [7.51483056e-01 2.48516944e-01]\n",
      " [4.95946240e-01 5.04053760e-01]\n",
      " [1.93721202e-01 8.06278798e-01]\n",
      " [6.13541826e-01 3.86458174e-01]\n",
      " [2.52143182e-01 7.47856818e-01]\n",
      " [2.55958189e-01 7.44041811e-01]\n",
      " [9.81377001e-01 1.86229986e-02]\n",
      " [4.78769021e-01 5.21230979e-01]\n",
      " [5.59115560e-01 4.40884440e-01]\n",
      " [6.23029913e-01 3.76970087e-01]\n",
      " [2.80362871e-01 7.19637129e-01]\n",
      " [8.65507920e-01 1.34492080e-01]\n",
      " [2.76475832e-01 7.23524168e-01]\n",
      " [3.38912010e-01 6.61087990e-01]\n",
      " [6.41216977e-01 3.58783023e-01]\n",
      " [2.99253849e-01 7.00746151e-01]\n",
      " [5.44291869e-01 4.55708131e-01]\n",
      " [9.28375570e-01 7.16244300e-02]\n",
      " [4.36435486e-01 5.63564514e-01]\n",
      " [4.48719630e-01 5.51280370e-01]\n",
      " [5.07962827e-01 4.92037173e-01]\n",
      " [9.94657769e-01 5.34223117e-03]\n",
      " [3.99083656e-01 6.00916344e-01]\n",
      " [9.84653716e-01 1.53462839e-02]\n",
      " [2.40361229e-01 7.59638771e-01]\n",
      " [1.96251862e-01 8.03748138e-01]\n",
      " [4.41837340e-01 5.58162660e-01]\n",
      " [3.71555286e-01 6.28444714e-01]\n",
      " [4.16278749e-01 5.83721251e-01]\n",
      " [4.90717285e-01 5.09282715e-01]\n",
      " [3.86693119e-01 6.13306881e-01]\n",
      " [5.04880257e-01 4.95119743e-01]\n",
      " [5.78635648e-01 4.21364352e-01]\n",
      " [3.43762695e-01 6.56237305e-01]\n",
      " [2.67139390e-01 7.32860610e-01]\n",
      " [2.36296408e-01 7.63703592e-01]\n",
      " [4.65278494e-01 5.34721506e-01]\n",
      " [3.20474540e-01 6.79525460e-01]\n",
      " [4.73183090e-01 5.26816910e-01]\n",
      " [3.54422125e-01 6.45577875e-01]\n",
      " [5.33661047e-01 4.66338953e-01]\n",
      " [2.03886229e-01 7.96113771e-01]\n",
      " [4.48719630e-01 5.51280370e-01]\n",
      " [9.87652263e-01 1.23477370e-02]\n",
      " [9.99366446e-01 6.33554198e-04]\n",
      " [6.24063532e-01 3.75936468e-01]\n",
      " [5.17864229e-01 4.82135771e-01]\n",
      " [2.67354264e-01 7.32645736e-01]\n",
      " [2.67139390e-01 7.32860610e-01]\n",
      " [9.06908945e-01 9.30910548e-02]\n",
      " [5.17494684e-01 4.82505316e-01]\n",
      " [9.85796068e-01 1.42039319e-02]\n",
      " [3.59902514e-01 6.40097486e-01]\n",
      " [3.39437148e-01 6.60562852e-01]\n",
      " [2.94134962e-01 7.05865038e-01]\n",
      " [4.28173696e-01 5.71826304e-01]\n",
      " [3.16361934e-01 6.83638066e-01]\n",
      " [3.34862489e-01 6.65137511e-01]\n",
      " [6.24998908e-01 3.75001092e-01]\n",
      " [3.40317014e-01 6.59682986e-01]\n",
      " [5.44186128e-01 4.55813872e-01]\n",
      " [9.93221327e-01 6.77867329e-03]\n",
      " [5.04024496e-01 4.95975504e-01]\n",
      " [4.48357488e-01 5.51642512e-01]\n",
      " [2.52143182e-01 7.47856818e-01]\n",
      " [3.20044154e-01 6.79955846e-01]\n",
      " [4.14636540e-01 5.85363460e-01]\n",
      " [4.16278749e-01 5.83721251e-01]\n",
      " [2.36296408e-01 7.63703592e-01]\n",
      " [8.16167661e-01 1.83832339e-01]\n",
      " [9.75888263e-01 2.41117369e-02]\n",
      " [9.97412674e-01 2.58732613e-03]\n",
      " [8.48185004e-01 1.51814996e-01]\n",
      " [2.74392538e-01 7.25607462e-01]\n",
      " [2.79377610e-01 7.20622390e-01]\n",
      " [7.43824654e-01 2.56175346e-01]\n",
      " [6.98368837e-01 3.01631163e-01]\n",
      " [2.76906111e-01 7.23093889e-01]\n",
      " [7.23314571e-01 2.76685429e-01]\n",
      " [4.00786193e-01 5.99213807e-01]\n",
      " [5.59984741e-01 4.40015259e-01]\n",
      " [4.95484954e-01 5.04515046e-01]\n",
      " [9.99999996e-01 3.82318647e-09]\n",
      " [3.73799219e-01 6.26200781e-01]\n",
      " [3.39390405e-01 6.60609595e-01]\n",
      " [3.59902514e-01 6.40097486e-01]\n",
      " [2.36222425e-01 7.63777575e-01]\n",
      " [9.99264886e-01 7.35113657e-04]\n",
      " [3.96666259e-01 6.03333741e-01]\n",
      " [3.51782912e-01 6.48217088e-01]\n",
      " [3.86668475e-01 6.13331525e-01]\n",
      " [9.99914177e-01 8.58233212e-05]\n",
      " [4.00553911e-01 5.99446089e-01]\n",
      " [3.25659446e-01 6.74340554e-01]\n",
      " [3.22688115e-01 6.77311885e-01]\n",
      " [6.87566426e-01 3.12433574e-01]\n",
      " [3.90944937e-01 6.09055063e-01]\n",
      " [2.76475832e-01 7.23524168e-01]\n",
      " [4.73183090e-01 5.26816910e-01]\n",
      " [3.59902514e-01 6.40097486e-01]\n",
      " [8.71259539e-01 1.28740461e-01]\n",
      " [9.97463580e-01 2.53641951e-03]\n",
      " [6.62673203e-01 3.37326797e-01]\n",
      " [2.54731258e-01 7.45268742e-01]\n",
      " [4.03362573e-01 5.96637427e-01]\n",
      " [7.19444748e-01 2.80555252e-01]\n",
      " [4.35707425e-01 5.64292575e-01]\n",
      " [3.04171936e-01 6.95828064e-01]\n",
      " [9.84400337e-01 1.55996627e-02]\n",
      " [4.90165428e-01 5.09834572e-01]\n",
      " [9.97311630e-01 2.68836990e-03]\n",
      " [9.56249037e-01 4.37509633e-02]\n",
      " [4.18448372e-01 5.81551628e-01]\n",
      " [3.82173477e-01 6.17826523e-01]\n",
      " [3.50528934e-01 6.49471066e-01]\n",
      " [7.43824654e-01 2.56175346e-01]\n",
      " [9.54026211e-01 4.59737887e-02]\n",
      " [2.80477662e-01 7.19522338e-01]\n",
      " [2.26203255e-01 7.73796745e-01]\n",
      " [2.14886492e-01 7.85113508e-01]\n",
      " [3.57409040e-01 6.42590960e-01]\n",
      " [3.11563412e-01 6.88436588e-01]\n",
      " [9.99999999e-01 1.46670407e-09]\n",
      " [3.89711449e-01 6.10288551e-01]\n",
      " [3.07720677e-01 6.92279323e-01]\n",
      " [3.44289088e-01 6.55710912e-01]\n",
      " [2.92473007e-01 7.07526993e-01]\n",
      " [5.42586798e-01 4.57413202e-01]\n",
      " [4.09851104e-01 5.90148896e-01]\n",
      " [4.44633512e-01 5.55366488e-01]\n",
      " [3.51782912e-01 6.48217088e-01]\n",
      " [2.47915849e-01 7.52084151e-01]\n",
      " [2.21943661e-01 7.78056339e-01]\n",
      " [2.45472651e-01 7.54527349e-01]\n",
      " [4.14636540e-01 5.85363460e-01]\n",
      " [3.54422125e-01 6.45577875e-01]\n",
      " [1.90264183e-01 8.09735817e-01]\n",
      " [2.91048560e-01 7.08951440e-01]\n",
      " [1.94355672e-01 8.05644328e-01]\n",
      " [9.74479285e-01 2.55207148e-02]\n",
      " [3.05484515e-01 6.94515485e-01]\n",
      " [9.63765249e-01 3.62347509e-02]\n",
      " [3.22244076e-01 6.77755924e-01]\n",
      " [5.37069571e-01 4.62930429e-01]\n",
      " [4.38578155e-01 5.61421845e-01]\n",
      " [4.81932647e-01 5.18067353e-01]\n",
      " [5.17281467e-01 4.82718533e-01]\n",
      " [9.84155739e-01 1.58442612e-02]\n",
      " [7.03083157e-01 2.96916843e-01]\n",
      " [4.84016945e-01 5.15983055e-01]\n",
      " [3.39390405e-01 6.60609595e-01]\n",
      " [5.95428184e-01 4.04571816e-01]\n",
      " [7.86755478e-01 2.13244522e-01]\n",
      " [3.02886834e-01 6.97113166e-01]\n",
      " [5.84080735e-01 4.15919265e-01]\n",
      " [4.90165428e-01 5.09834572e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = classifier.predict_proba(X_test)\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72 58]\n",
      " [21 99]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.55      0.65       130\n",
      "         1.0       0.63      0.82      0.71       120\n",
      "\n",
      "    accuracy                           0.68       250\n",
      "   macro avg       0.70      0.69      0.68       250\n",
      "weighted avg       0.71      0.68      0.68       250\n",
      "\n",
      "Accracy of the model: 0.684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusting the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors at threshold  0.4 : 77  , type 2 error : 5  , type 1 error: 72\n",
      "Errors at threshold  0.41000000000000003 : 77  , type 2 error : 6  , type 1 error: 71\n",
      "Errors at threshold  0.42000000000000004 : 77  , type 2 error : 7  , type 1 error: 70\n",
      "Errors at threshold  0.43000000000000005 : 78  , type 2 error : 9  , type 1 error: 69\n",
      "Errors at threshold  0.44000000000000006 : 77  , type 2 error : 9  , type 1 error: 68\n",
      "Errors at threshold  0.45000000000000007 : 77  , type 2 error : 10  , type 1 error: 67\n",
      "Errors at threshold  0.4600000000000001 : 81  , type 2 error : 15  , type 1 error: 66\n",
      "Errors at threshold  0.4700000000000001 : 81  , type 2 error : 16  , type 1 error: 65\n",
      "Errors at threshold  0.4800000000000001 : 82  , type 2 error : 17  , type 1 error: 65\n",
      "Errors at threshold  0.4900000000000001 : 80  , type 2 error : 18  , type 1 error: 62\n",
      "Errors at threshold  0.5000000000000001 : 79  , type 2 error : 21  , type 1 error: 58\n",
      "Errors at threshold  0.5100000000000001 : 81  , type 2 error : 25  , type 1 error: 56\n",
      "Errors at threshold  0.5200000000000001 : 78  , type 2 error : 27  , type 1 error: 51\n",
      "Errors at threshold  0.5300000000000001 : 79  , type 2 error : 29  , type 1 error: 50\n",
      "Errors at threshold  0.5400000000000001 : 79  , type 2 error : 30  , type 1 error: 49\n",
      "Errors at threshold  0.5500000000000002 : 79  , type 2 error : 31  , type 1 error: 48\n",
      "Errors at threshold  0.5600000000000002 : 78  , type 2 error : 33  , type 1 error: 45\n",
      "Errors at threshold  0.5700000000000002 : 81  , type 2 error : 37  , type 1 error: 44\n",
      "Errors at threshold  0.5800000000000002 : 84  , type 2 error : 41  , type 1 error: 43\n",
      "Errors at threshold  0.5900000000000002 : 91  , type 2 error : 49  , type 1 error: 42\n",
      "Errors at threshold  0.6000000000000002 : 92  , type 2 error : 52  , type 1 error: 40\n"
     ]
    }
   ],
   "source": [
    "for a in np.arange(0.4,0.61,0.01):\n",
    "    predict_mine = np.where(y_pred_prob[:,1] > a, 1, 0)\n",
    "    cfm=confusion_matrix(Y_test, predict_mine)\n",
    "    total_err=cfm[0,1]+cfm[1,0]\n",
    "    print(\"Errors at threshold \", a, \":\",total_err, \" , type 2 error :\",\n",
    "    cfm[1,0],\" , type 1 error:\", cfm[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class=[]\n",
    "for value in y_pred_prob[:,1]:\n",
    "    if value >0.55:\n",
    "        y_pred_class.append(1)\n",
    "    else:\n",
    "        y_pred_class.append(0)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82 48]\n",
      " [31 89]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.63      0.67       130\n",
      "         1.0       0.65      0.74      0.69       120\n",
      "\n",
      "    accuracy                           0.68       250\n",
      "   macro avg       0.69      0.69      0.68       250\n",
      "weighted avg       0.69      0.68      0.68       250\n",
      "\n",
      "Accracy of the model: 0.684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,y_pred_class)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,y_pred_class))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,y_pred_class)\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=10, splitter='best')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion=\"gini\",random_state=10)\n",
    "model_DecisionTree.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "print(list(zip(Y_pred,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90  40]\n",
      " [ 11 109]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.69      0.78       130\n",
      "         1.0       0.73      0.91      0.81       120\n",
      "\n",
      "    accuracy                           0.80       250\n",
      "   macro avg       0.81      0.80      0.79       250\n",
      "weighted avg       0.81      0.80      0.79       250\n",
      "\n",
      "Accracy of the model: 0.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning the decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=10, splitter='best')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion=\"gini\",min_samples_leaf=5,max_depth=10,random_state=10)\n",
    "model_DecisionTree.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "print(list(zip(Y_pred,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 43]\n",
      " [21 99]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.67      0.73       130\n",
      "         1.0       0.70      0.82      0.76       120\n",
      "\n",
      "    accuracy                           0.74       250\n",
      "   macro avg       0.75      0.75      0.74       250\n",
      "weighted avg       0.75      0.74      0.74       250\n",
      "\n",
      "Accracy of the model: 0.744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(12,12,12),max_iter=100,early_stopping=True,random_state=10,activation=\"relu\")\n",
    "mlp.fit(X_train,Y_train)\n",
    "Y_pred=mlp.predict(X_test)\n",
    "print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75 55]\n",
      " [29 91]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.58      0.64       130\n",
      "         1.0       0.62      0.76      0.68       120\n",
      "\n",
      "    accuracy                           0.66       250\n",
      "   macro avg       0.67      0.67      0.66       250\n",
      "weighted avg       0.67      0.66      0.66       250\n",
      "\n",
      "Accracy of the model: 0.664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)#unneccessary dont prune the model on gud model coz if u do it would affect worse\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 1.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0), (0.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 0.0), (1.0, 1.0), (0.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 1.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (1.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0), (1.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#n_neighbors is passed to give the value of the K.\n",
    "#k value is passed as the sqrt of the number of observation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_KNN=KNeighborsClassifier(n_neighbors=int(round(np.sqrt(len(X_train)),0)),metric='manhattan')\n",
    "#fit the model on the data and predict the values\n",
    "model_KNN.fit(X_train,Y_train)\n",
    "Y_pred=model_KNN.predict(X_test)\n",
    "print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61  69]\n",
      " [ 11 109]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.47      0.60       130\n",
      "         1.0       0.61      0.91      0.73       120\n",
      "\n",
      "    accuracy                           0.68       250\n",
      "   macro avg       0.73      0.69      0.67       250\n",
      "weighted avg       0.73      0.68      0.67       250\n",
      "\n",
      "Accracy of the model: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)#unneccessary dont prune the model on gud model coz if u do it would affect worse\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.824 for K-Value: 1\n",
      "Accuracy is  0.76 for K-Value: 2\n",
      "Accuracy is  0.704 for K-Value: 3\n",
      "Accuracy is  0.7 for K-Value: 4\n",
      "Accuracy is  0.704 for K-Value: 5\n",
      "Accuracy is  0.7 for K-Value: 6\n",
      "Accuracy is  0.692 for K-Value: 7\n",
      "Accuracy is  0.696 for K-Value: 8\n",
      "Accuracy is  0.696 for K-Value: 9\n",
      "Accuracy is  0.68 for K-Value: 10\n",
      "Accuracy is  0.7 for K-Value: 11\n",
      "Accuracy is  0.696 for K-Value: 12\n",
      "Accuracy is  0.724 for K-Value: 13\n",
      "Accuracy is  0.704 for K-Value: 14\n",
      "Accuracy is  0.688 for K-Value: 15\n",
      "Accuracy is  0.68 for K-Value: 16\n",
      "Accuracy is  0.684 for K-Value: 17\n",
      "Accuracy is  0.68 for K-Value: 18\n",
      "Accuracy is  0.68 for K-Value: 19\n",
      "Accuracy is  0.684 for K-Value: 20\n",
      "Accuracy is  0.68 for K-Value: 21\n",
      "Accuracy is  0.684 for K-Value: 22\n",
      "Accuracy is  0.688 for K-Value: 23\n",
      "Accuracy is  0.68 for K-Value: 24\n",
      "Accuracy is  0.704 for K-Value: 25\n",
      "Accuracy is  0.708 for K-Value: 26\n",
      "Accuracy is  0.708 for K-Value: 27\n",
      "Accuracy is  0.696 for K-Value: 28\n",
      "Accuracy is  0.672 for K-Value: 29\n",
      "Accuracy is  0.684 for K-Value: 30\n",
      "Accuracy is  0.672 for K-Value: 31\n",
      "Accuracy is  0.664 for K-Value: 32\n",
      "Accuracy is  0.66 for K-Value: 33\n",
      "Accuracy is  0.664 for K-Value: 34\n",
      "Accuracy is  0.664 for K-Value: 35\n",
      "Accuracy is  0.668 for K-Value: 36\n",
      "Accuracy is  0.664 for K-Value: 37\n",
      "Accuracy is  0.668 for K-Value: 38\n",
      "Accuracy is  0.672 for K-Value: 39\n",
      "Accuracy is  0.676 for K-Value: 40\n",
      "Accuracy is  0.676 for K-Value: 41\n",
      "Accuracy is  0.664 for K-Value: 42\n",
      "Accuracy is  0.676 for K-Value: 43\n",
      "Accuracy is  0.672 for K-Value: 44\n",
      "Accuracy is  0.668 for K-Value: 45\n",
      "Accuracy is  0.668 for K-Value: 46\n",
      "Accuracy is  0.676 for K-Value: 47\n",
      "Accuracy is  0.688 for K-Value: 48\n",
      "Accuracy is  0.692 for K-Value: 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for K in range(1,50):\n",
    "    model_KNN = KNeighborsClassifier(K,metric=\"euclidean\")\n",
    "    model_KNN.fit(X_train, Y_train)\n",
    "    Y_pred = model_KNN.predict(X_test)\n",
    "    print (\"Accuracy is \", accuracy_score(Y_test,Y_pred), \"for K-Value:\",K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc_model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "svc_model.fit(X_train, Y_train)\n",
    "Y_pred=svc_model.predict(X_test)\n",
    "print(list(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70  60]\n",
      " [ 17 103]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.54      0.65       130\n",
      "         1.0       0.63      0.86      0.73       120\n",
      "\n",
      "    accuracy                           0.69       250\n",
      "   macro avg       0.72      0.70      0.69       250\n",
      "weighted avg       0.72      0.69      0.68       250\n",
      "\n",
      "Accracy of the model: 0.692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cfm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cfm)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))#recall is accuracy score for individual class. class 0 is called as specificity or TNR, class 1 is called sensitivity or TPR\n",
    "acc=accuracy_score(Y_test,Y_pred)#unneccessary dont prune the model on gud model coz if u do it would affect worse\n",
    "print(\"Accracy of the model:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model=ExtraTreesClassifier(30,random_state=10)\n",
    "#fit the model on the data and predict the values\n",
    "model=model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116  14]\n",
      " [  9 111]]\n",
      "\n",
      "0.908\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.89      0.91       130\n",
      "         1.0       0.89      0.93      0.91       120\n",
      "\n",
      "    accuracy                           0.91       250\n",
      "   macro avg       0.91      0.91      0.91       250\n",
      "weighted avg       0.91      0.91      0.91       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print()\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print()\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
